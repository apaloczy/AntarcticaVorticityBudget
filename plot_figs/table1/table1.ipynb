{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: Calculates correlations between daily vorticity terms.\n",
    "#\n",
    "# Author:      André Palóczy\n",
    "# E-mail:      paloczy@gmail.com\n",
    "# Date:        April/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xarray import open_dataset\n",
    "from pandas import Series\n",
    "from scipy.special import erfinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosscorr(x, y, nblks, maxlags=0, overlap=0, onesided=False, verbose=True):\n",
    "    \"\"\"\n",
    "    Lag-N cross correlation averaged with Welch's Method.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y     : Arrays of equal length.\n",
    "    nblks    : Number of blocks to average cross-correlation.\n",
    "    maxlags  : int, default (0) calculates te largest possible number of lags,\n",
    "               i.e., the number of points in each chunk.\n",
    "    overlap  : float, fraction of overlap between consecutive chunks. Default 0.\n",
    "    onesided : Whether to calculate the cross-correlation only at\n",
    "               positive lags (default False). Has no effect if\n",
    "               x and y are the same array, in which case the\n",
    "               one-sided autocorrelation function is calculated.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    crosscorr : float array.\n",
    "    \"\"\"\n",
    "    if x is y:\n",
    "        auto = True\n",
    "    else:\n",
    "        auto = False\n",
    "    x, y = np.array(x), np.array(y)\n",
    "    nx, ny = x.size, y.size\n",
    "    assert x.size==y.size, \"The series must have the same length\"\n",
    "\n",
    "    nblks, maxlags = int(nblks), int(maxlags)\n",
    "    ni = int(nx/nblks)               # Number of data points in each chunk.\n",
    "    dn = int(round(ni - overlap*ni)) # How many indices to move forward with\n",
    "                                     # each chunk (depends on the % overlap).\n",
    "\n",
    "    if maxlags==0:\n",
    "        if verbose:\n",
    "            print(\"Maximum lag was not specified. Accomodating it to block size (%d).\"%ni)\n",
    "        maxlags = ni\n",
    "    elif maxlags>ni:\n",
    "        if verbose:\n",
    "            print(\"Maximum lag is too large. Accomodating it to block size (%d).\"%ni)\n",
    "        maxlags = ni\n",
    "\n",
    "    if onesided:\n",
    "        lags = range(maxlags+1)\n",
    "    else:\n",
    "        lags = range(-maxlags, maxlags+1)\n",
    "\n",
    "    # Array that will receive cross-correlation of each block.\n",
    "    xycorr = np.zeros(len(lags))\n",
    "\n",
    "    n=0\n",
    "    il, ir = 0, ni\n",
    "    while ir<=nx:\n",
    "        xn = x[il:ir]\n",
    "        yn = y[il:ir]\n",
    "\n",
    "        # Calculate cross-correlation for current block up to desired maximum lag - 1.\n",
    "        xn, yn = map(Series, (xn, yn))\n",
    "        xycorr += np.array([xn.corr(yn.shift(periods=lagn)) for lagn in lags])\n",
    "\n",
    "        il+=dn; ir+=dn\n",
    "        n+=1\n",
    "\n",
    "    # pandas.Series.corr(method='pearson') -> pandas.nanops.nancorr() ...\n",
    "    # -> pandas.nanops.get_corr_function() -> np.corrcoef -> numpy.cov(bias=False as default).\n",
    "    # So np.corrcoef() returns the UNbiased correlation coefficient by default\n",
    "    # (i.e., normalized by N-k instead of N).\n",
    "\n",
    "    xycorr /= n    # Divide by number of blocks actually used.\n",
    "    ncap = nx - il # Number of points left out at the end of array.\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\")\n",
    "        if ncap==0:\n",
    "            print(\"No data points were left out.\")\n",
    "        else:\n",
    "            print(\"Left last %d data points out (%.1f %% of all points).\"%(ncap,100*ncap/nx))\n",
    "        print(\"Averaged %d blocks, each with %d lags.\"%(n,maxlags))\n",
    "        if overlap>0:\n",
    "            print(\"Intended %d blocks, but could fit %d blocks, with\"%(nblks,n))\n",
    "            print('overlap of %.1f %%, %d points per block.'%(100*overlap,dn))\n",
    "        print(\"\")\n",
    "\n",
    "    lags = np.array(lags)\n",
    "    if auto and not onesided:\n",
    "        fo = np.where(lags==0)[0][0]\n",
    "        xycorr[fo+1:] = xycorr[fo+1:] + xycorr[:fo]\n",
    "        lags = lags[fo:]\n",
    "        xycorr = xycorr[fo:]\n",
    "\n",
    "    fgud=~np.isnan(xycorr)\n",
    "\n",
    "    return lags[fgud], xycorr[fgud]\n",
    "\n",
    "\n",
    "def Tdecorr(Rxx, M=None, dtau=1., verbose=False):\n",
    "    \"\"\"\n",
    "    USAGE\n",
    "    -----\n",
    "    Td = Tdecorr(Rxx)\n",
    "\n",
    "    Computes the integral scale Td (AKA decorrelation scale, independence scale)\n",
    "    for a data sequence with autocorrelation function Rxx. 'M' is the number of\n",
    "    lags to incorporate in the summation (defaults to all lags) and 'dtau' is the\n",
    "    lag time step (defaults to 1).\n",
    "\n",
    "    The formal definition of the integral scale is the total area under the\n",
    "    autocorrelation curve Rxx(tau):\n",
    "\n",
    "    /+inf\n",
    "    Td = 2 * |     Rxx(tau) dtau\n",
    "    /0\n",
    "\n",
    "    In practice, however, Td may become unrealistic if all of Rxx is summed\n",
    "    (e.g., often goes to zero for data dominated by periodic signals); a\n",
    "    different approach is to instead change M in the summation and use the\n",
    "    maximum value of the integral Td(t):\n",
    "\n",
    "    /t\n",
    "    Td(t) = 2 * |     Rxx(tau) dtau\n",
    "    /0\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    e.g., Thomson and Emery (2014),\n",
    "    Data analysis methods in physical oceanography,\n",
    "    p. 274, equation 3.137a.\n",
    "\n",
    "    Gille lecture notes on data analysis, available\n",
    "    at http://www-pord.ucsd.edu/~sgille/mae127/lecture10.pdf\n",
    "    \"\"\"\n",
    "    Rxx = np.asanyarray(Rxx)\n",
    "    C0 = Rxx[0]\n",
    "    N = Rxx.size # Sequence size.\n",
    "\n",
    "    # Number of lags 'M' to incorporate in the summation.\n",
    "    # Sum over all of the sequence if M is not chosen.\n",
    "    if not M:\n",
    "        M = N\n",
    "\n",
    "    # Integrate the autocorrelation function.\n",
    "    Td = np.zeros(M)\n",
    "    for m in range(M):\n",
    "        Tdaux = 0.\n",
    "        for k in range(m-1):\n",
    "            Rm = (Rxx[k] + Rxx[k+1])/2. # Midpoint value of the autocorrelation function.\n",
    "            Tdaux = Tdaux + Rm*dtau # Riemann-summing Rxx.\n",
    "\n",
    "        Td[m] = Tdaux\n",
    "\n",
    "    # Normalize the integral function by the autocorrelation at zero lag\n",
    "    # and double it to include the contribution of the side with\n",
    "    # negative lags (C is symmetric about zero).\n",
    "    Td = (2./C0)*Td\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\")\n",
    "        print(\"Theoretical integral scale --> 2 * int 0...+inf [Rxx(tau)] dtau: %.2f.\"%Td[-1])\n",
    "        print(\"\")\n",
    "        print(\"Maximum value of the cumulative sum: %.2f.\"%Td.max())\n",
    "\n",
    "    return Td\n",
    "\n",
    "\n",
    "def Tdecorrw(x, nblks=30, ret_median=True, verbose=True):\n",
    "    \"\"\"\n",
    "    USAGE\n",
    "    -----\n",
    "    Ti = Tdecorrw(x, nblks=30, ret_median=True, verbose=True)\n",
    "\n",
    "    'Ti' is the integral timescale calculated from the\n",
    "    autocorrelation function calculated for variable 'x'\n",
    "    block-averaged in 'nblks' chunks.\n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    dnblkslr = round(nblks/2)\n",
    "\n",
    "    tis = [Tdecorr(crosscorr(x, x, nblks=n, verbose=verbose)[1]).max() for n in range(nblks-dnblkslr, nblks+dnblkslr+1)]\n",
    "    tis = np.ma.masked_invalid(tis)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"========================\")\n",
    "        print(tis)\n",
    "        print(\"========================\")\n",
    "        p1, p2, p3, p4, p5 = map(np.percentile, [tis]*5, (10, 25, 50, 75, 90))\n",
    "        print(\"--> 10 %%, 25 %%, 50 %%, 75 %%, 90 %% percentiles for Ti:  %.2f,  %.2f,  %.2f,  %.2f,  %.2f.\"%(p1, p2, p3, p4, p5))\n",
    "        print(\"------------------------\")\n",
    "\n",
    "    if ret_median:\n",
    "        return np.median(tis)\n",
    "    else:\n",
    "        return tis\n",
    "\n",
    "\n",
    "def rsig(ndof_eff, alpha=0.95):\n",
    "\t\"\"\"\n",
    "\tUSAGE\n",
    "\t-----\n",
    "\tRsig = rsig(ndof_eff, alpha=0.95)\n",
    "\n",
    "\tComputes the minimum (absolute) threshold value 'rsig' that\n",
    "\tthe Pearson correlation coefficient r between two normally-distributed\n",
    "\tdata sequences with 'ndof_eff' effective degrees of freedom has to have\n",
    "\tto be statistically significant at the 'alpha' (defaults to 0.95)\n",
    "\tconfidence level.\n",
    "\n",
    "\tFor example, if rsig(ndof_eff, alpha=0.95) = 0.2 for a given pair of\n",
    "\tNORMALLY-DISTRIBUTED samples with a correlation coefficient r>0.7, there\n",
    "\tis a 95 % chance that the r estimated from the samples is significantly\n",
    "\tdifferent from zero. In other words, there is a 5 % chance that two random\n",
    "\tsequences would have a correlation coefficient higher than 0.7.\n",
    "\n",
    "\tOBS: This assumes that the two data series have a normal distribution.\n",
    "\n",
    "\tTranslated to Python from the original matlab code by Prof. Sarah Gille\n",
    "\t(significance.m), available at http://www-pord.ucsd.edu/~sgille/sio221c/\n",
    "\n",
    "\tReferences\n",
    "\t----------\n",
    "\tGille lecture notes on data analysis, available\n",
    "\tat http://www-pord.ucsd.edu/~sgille/mae127/lecture10.pdf\n",
    "\n",
    "\tExample\n",
    "\t-------\n",
    "\tTODO\n",
    "\t\"\"\"\n",
    "\trcrit_z = erfinv(alpha)*np.sqrt(2./ndof_eff)\n",
    "\n",
    "\treturn rcrit_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "../../data_reproduce_figs/circulation_terms-Amundsen-Bellingshausen.nc *******************************\n",
      "****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/anaconda3/envs/py3/lib/python3.7/site-packages/numpy/lib/function_base.py:2526: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar)\n",
      "/home/andre/anaconda3/envs/py3/lib/python3.7/site-packages/numpy/lib/function_base.py:2455: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TSB: Zero-lag correlation of 'Icurlvvdiff' with (beta*V + f*wI) is 0.54.\n",
      "tTSB: Zero-lag correlation of 'Icurlvvdiff' with (beta*V + f*wI + dzeta/dt) is 0.94.\n",
      "\n",
      "../../data_reproduce_figs/circulation_terms-WAP.nc *******************************\n",
      "****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/anaconda3/envs/py3/lib/python3.7/site-packages/numpy/lib/function_base.py:2526: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar)\n",
      "/home/andre/anaconda3/envs/py3/lib/python3.7/site-packages/numpy/lib/function_base.py:2455: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TSB: Zero-lag correlation of 'Icurlvvdiff' with (beta*V + f*wI) is 0.18.\n",
      "tTSB: Zero-lag correlation of 'Icurlvvdiff' with (beta*V + f*wI + dzeta/dt) is 0.11.\n",
      "\n",
      "../../data_reproduce_figs/circulation_terms-Weddell.nc *******************************\n",
      "****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/anaconda3/envs/py3/lib/python3.7/site-packages/numpy/lib/function_base.py:2526: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar)\n",
      "/home/andre/anaconda3/envs/py3/lib/python3.7/site-packages/numpy/lib/function_base.py:2455: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TSB: Zero-lag correlation of 'Icurlvvdiff' with (beta*V + f*wI) is 0.36.\n",
      "tTSB: Zero-lag correlation of 'Icurlvvdiff' with (beta*V + f*wI + dzeta/dt) is 0.74.\n",
      "\n",
      "../../data_reproduce_figs/circulation_terms-W-EA.nc *******************************\n",
      "****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/anaconda3/envs/py3/lib/python3.7/site-packages/numpy/lib/function_base.py:2526: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar)\n",
      "/home/andre/anaconda3/envs/py3/lib/python3.7/site-packages/numpy/lib/function_base.py:2455: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TSB: Zero-lag correlation of 'Icurlvvdiff' with (beta*V + f*wI) is 0.36.\n",
      "tTSB: Zero-lag correlation of 'Icurlvvdiff' with (beta*V + f*wI + dzeta/dt) is 0.52.\n",
      "\n",
      "../../data_reproduce_figs/circulation_terms-E-EA.nc *******************************\n",
      "****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/anaconda3/envs/py3/lib/python3.7/site-packages/numpy/lib/function_base.py:2526: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar)\n",
      "/home/andre/anaconda3/envs/py3/lib/python3.7/site-packages/numpy/lib/function_base.py:2455: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TSB: Zero-lag correlation of 'Icurlvvdiff' with (beta*V + f*wI) is 0.26.\n",
      "tTSB: Zero-lag correlation of 'Icurlvvdiff' with (beta*V + f*wI + dzeta/dt) is 0.63.\n",
      "\n",
      "../../data_reproduce_figs/circulation_terms-Ross.nc *******************************\n",
      "****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/anaconda3/envs/py3/lib/python3.7/site-packages/numpy/lib/function_base.py:2526: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar)\n",
      "/home/andre/anaconda3/envs/py3/lib/python3.7/site-packages/numpy/lib/function_base.py:2455: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TSB: Zero-lag correlation of 'Icurlvvdiff' with (beta*V + f*wI) is 0.19.\n",
      "tTSB: Zero-lag correlation of 'Icurlvvdiff' with (beta*V + f*wI + dzeta/dt) is 0.48.\n",
      "\n",
      "../../data_reproduce_figs/circulation_terms_circumpolar.nc *******************************\n",
      "****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/anaconda3/envs/py3/lib/python3.7/site-packages/numpy/lib/function_base.py:2526: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar)\n",
      "/home/andre/anaconda3/envs/py3/lib/python3.7/site-packages/numpy/lib/function_base.py:2455: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TSB: Zero-lag correlation of 'Icurlvvdiff' with (beta*V + f*wI) is 0.40.\n",
      "tTSB: Zero-lag correlation of 'Icurlvvdiff' with (beta*V + f*wI + dzeta/dt) is 0.61.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plt.close('all')\n",
    "\n",
    "head_data = \"../../data_reproduce_figs/\"\n",
    "terms = ['Ibetav', 'Icurlvdiff', 'Icurlhdiff', 'Istretchp', 'Ires', 'Icurlnonl']\n",
    "segments = ['Amundsen-Bellingshausen', 'WAP', 'Weddell', 'W-EA', 'E-EA', 'Ross']\n",
    "\n",
    "term_label = dict(Ibetav=r\"$-\\beta V$\", Icurlvdiff=r\"VVIS$_\\xi$\", Icurlhdiff=r\"HVIS$_\\xi$\", Istretchp=r\"$-fw_I$\", Ires=r\"-$\\zeta_t$\", Icurlnonl=r\"-NONL$_\\xi$\", Ierrcor=r\"-ERRCOR\")\n",
    "\n",
    "# Circumpolar circulation terms.\n",
    "fname = head_data+'circulation_terms_circumpolar.nc'\n",
    "ds = open_dataset(fname)\n",
    "\n",
    "# Line plot with 2005-2009 time series of all circumpolar terms.\n",
    "t = ds['t']\n",
    "\n",
    "if False:\n",
    "\tTi = dict()\n",
    "\tfor term in terms:\n",
    "\t\tplt.plot(t, ds[term].values, label=term_label[term])\n",
    "\t\tTi.update({term:Tdecorrw(ds[term].values)})\n",
    "\tplt.legend()\n",
    "\n",
    "\tEDoF = 365\n",
    "\trmin = rsig(EDoF, alpha=0.99)\n",
    "\tprint(\"Minimum statistically significant correlation coeff at 0.95 CL: %.2f\"%rmin)\n",
    "\n",
    "if False:\n",
    "\tF = ds['Icurlvdiff']\n",
    "\tR_TSB = -ds['Ibetav'] - ds['Istretchp']\n",
    "\tR_tTSB = -ds['Ibetav'] - ds['Istretchp'] + ds['Ires']\n",
    "\n",
    "\tF_Ti = Tdecorrw(F.values)\n",
    "\tR_TSB_Ti = Tdecorrw(R_TSB.values)\n",
    "\tR_tTSB_Ti = Tdecorrw(R_tTSB.values)\n",
    "\n",
    "# Integral timescales for the circumpolar average of F and R.\n",
    "# Choose the conservative value of 5 days for all -> Neff = T/Ti = 1825 days/5 days = 365 EDoF.*****\n",
    "#\n",
    "# In [36]: F_Ti\n",
    "# Out[36]: 2.6560768522084586\n",
    "#\n",
    "# In [37]: R_TSB_Ti\n",
    "# Out[37]: 2.291490519265456\n",
    "#\n",
    "# In [38]: R_tTSB_Ti\n",
    "# Out[38]: 0.8437070018333408\n",
    "\n",
    "# Cross-correlations between terms and autocorrelations.\n",
    "nblks_corr = 100\n",
    "\n",
    "fnames = [head_data+'circulation_terms-Amundsen-Bellingshausen.nc',\n",
    "          head_data+'circulation_terms-WAP.nc',\n",
    "          head_data+'circulation_terms-Weddell.nc',\n",
    "          head_data+'circulation_terms-W-EA.nc',\n",
    "          head_data+'circulation_terms-E-EA.nc',\n",
    "          head_data+'circulation_terms-Ross.nc',\n",
    "          head_data+'circulation_terms_circumpolar.nc',]\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "n=0\n",
    "for fname in fnames:\n",
    "  print(fname,\"*******************************\")\n",
    "  print(\"****************************************\")\n",
    "  ds = open_dataset(fname)\n",
    "  segment = fname.split('terms')[-1].split('.')[0][1:]\n",
    "\n",
    "  F = ds['Icurlvdiff'].values\n",
    "  TSB = -ds['Ibetav'].values - ds['Istretchp'].values # +beta*V +f*w_I, on LHS.\n",
    "  tTSB = -ds['Ibetav'].values - ds['Istretchp'].values + ds['Ires'].values # +beta*V +f*w_I + dzeta/dt, on LHS.\n",
    "\n",
    "  # Test Topographic Sverdrup Balance.\n",
    "  R = TSB\n",
    "  lags, FRcorr = crosscorr(F, R, nblks_corr, onesided=False, verbose=False)\n",
    "  fmaxcorr = np.where(lags==0)[0][0]\n",
    "  print(\"\")\n",
    "  print(\"TSB: Zero-lag correlation of 'Icurlvvdiff' with (beta*V + f*wI) is %.2f.\"%FRcorr[fmaxcorr])\n",
    "\n",
    "  # Test Transient Topographic Sverdrup Balance.\n",
    "  R = tTSB\n",
    "  lags, FRcorr = crosscorr(F, R, nblks_corr, onesided=False, verbose=False)\n",
    "  fmaxcorr = np.where(lags==0)[0][0]\n",
    "  print(\"tTSB: Zero-lag correlation of 'Icurlvvdiff' with (beta*V + f*wI + dzeta/dt) is %.2f.\"%FRcorr[fmaxcorr])\n",
    "  print(\"\")\n",
    "\n",
    "  n+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
